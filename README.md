# Walmart-Recruiting---Store-Sales-Forecasting

მოცემული გვქონდა Walmart-ის სხვადასხვა რეგიონში მდებარე 45 მაღაზიის გაყიდვების მონაცემები 2010-2012 წლებში. მიზანი იყო თითოეული მაღაზიის მასშტაბით გაყიდვების პროგნოზირება. 
გადმოგვეცემოდა შემდეგი ფაილები : 
train.csv მთავარი სატრენინგო ფაილი 5 სვეტით :  Store, Dept, Date, Weekly_Sales (target), isHoliday.
test.csv სატესტო ფაილი. იგივე რაც train.csv Weekly_Sales გარეშე.
და features.csv - დამატებითი მონაცემებისთვის, როგორიცაა ტემპერატურა, საწვავის ფასი, ფასდაკლების კვირეული, უმუშევრობისა და სამომხმარებლო ფასების ინდექსი.
ასევე გადმოცემული გვქონდა 4 კონკრეტული დღესასწაულის თარიღები: Super Bowl, Labor Day, მადლიერების დღე და შობა.

**მონაცემების ანალიზი :** ავაგეთ სხვადასხვა პლოტი, რომ დაგვენახა ზოგადი ტრენდი, სეზონურობა, თუ რა მნიშვნელობა ჰქონდა გაყიდვებზე მაღაზიის ტიპსა თუ დეპარტამენტს, რამდენად განმსაზღვრელი იყო დღესასწაულის პერიოდი, რა კორელაცია იყო ფიჩერებს შორის. გამოვიყენეთ ავტოკორელაციისა და  ნაწილობრივი ავტოკორელაციის ფუნქციაც.



**ტესტირებული მოდელები :**

**Deep Learning მოდელები**

1. **N-BEATS** (Neural Basis Expansion Analysis for Time Series) იყენებს ბლოკებს. ეს ბლოკები ერთმანეთზე სტეკივით ლაგდება. მექანიზმი ასეთია : პირველი ბლოკი ცდილობს წარსულის ახსნას (backcast), გარკვეული პატერნის, ტრენდის ან სეზონურობის. შემდეგ იწინასწარმეტყველებს მომავლის გარკვეულ ნაწილს (forecast). მეორე ბლოკი უკვე პირველის backcast-ის გარეშე არსებულ ინფორმაციას შეხედავს და ა.შ. ეს მოდელი N-BEATSx-გან განსხვავებით უყურებს მხოლოდ target მნიშვნელობებს და დამატებით ინფორმაციას არ ითვალისწინებს უკეთესი წინასწარმეტყველებისთვის.
ასე რომ, პრეპროცესინგი აღარ იყო საჭირო. გამოვიყენე neuralforecast ბიბლიოთეკა. შევქმენი ქვეკლასი N_beats, დავარეგულირე gamma (learning rate რამდენად მცირდება), input_size (რამდენი კვირის ინფორმაცია გადაეცემა მოდელს წინასწარმეტყველებისთვის), horizon (რამდენი კვირა უნდა იწინასწარმეტყველოს), stack types (როგორ ბლოკებს იყენებს მოდელი პატერნების დასაჭერად. ძირითადია შემდეგი 3 : identity, trend, seasonality), number of blocks, batch size. საბოლოო wmae მივიღე 2087

2. **DLinear (Decomposition Linear)** არის სპეციალური მოდელი დროის სერიების პროგნოზირებისთვის, რომელიც ეფუძნება დეკომპოზიციის პრინციპს. მოდელი მონაცემებს ყოფს ორ ნაწილად: ტრენდად და სეზონურობად. ტრენდი წარმოადგენს გრძელვადიან მიმართულებას და მიიღება AvgPool1d ფუნქციით, რომელიც აქ საშუალოდ 25 კვირის მოძრავ საშუალოს გამოითვლის. სეზონურობა კი მოიცავს განმეორებად პატერნებს დროის განმავლობაში, რომელიც მიიღება თავდაპირველი სიგნალიდან ტრენდის გამოკლებით.
DLinear მუშაობს 12 კვირიანი ისტორიის საფუძველზე. თითოეული ფიჩერისთვის ცალ-ცალკე ხდება ტრენდის და სეზონურობის გამოყოფა, რის შემდეგაც ორი დამოუკიდებელი Linear ფენა სწავლობს ამ ორ კომპონენტს. საბოლოო პროგნოზი მიიღება ამ ორი კომპონენტის ჯამით.
პრეპროცესინგის ეტაპზე, დავამატე 90 ფიჩერი, რომლებიც მოიცავდა დროის მახასიათებლებს, დღესასწაულებს, lag მნიშვნელობებს, მაღაზია-დეპარტამენტის სტატისტიკას, ფასდაკლებებს და ეკონომიკურ ინდიკატორებს. ფიჩერების არჩევისთვის გამოვიყენე SelectKBest, რის შედეგადაც ავარჩიე საუკეთესო 30 ფიჩერი. მონაცემების ნორმალიზაციისთვის გამოვიყენე StandardScaler.
შედეგების მიხედვით, DLinear მოდელმა აჩვენა WMAE = 2528.44 და R² = 0.92, რაც საკმაოდ მაღალი სიზუსტეა. მოდელი გავწვრთენი Early Stopping-ით 100 ეპოქამდე, ხოლო სასწავლო პროცესში გამოვიყენე Adam optimizer learning rate scheduling-ით, სადაც საწყისი learning rate იყო 0.003 და ეტაპობრივად მცირდებოდა 0.00005-მდე.

3. **PatchTST (Patching Time Series Transformer)** არის თანამედროვე Deep Learning მოდელი, რომელიც ეფუძნება Transformer არქიტექტურას და გამოიყენება დროითი მწკრივების პროგნოზირებისთვის. მოდელის მთავარი მექანიზმი არის დროითი მწკრივის დაყოფა პატარა "პატჩებად" (patches), რომლებიც შემდეგ გადაეცემა Transformer-ის ბლოკებს. ეს მიდგომა მნიშვნელოვნად ამცირებს გამოთვლით სირთულეს და საშუალებას აძლევს მოდელს ერთდროულად დაინახოს როგორც ლოკალური, ასევე გლობალური პატერნები. Self-attention მექანიზმი ეხმარება სხვადასხვა დროის პერიოდებს შორის კავშირების ეფექტურად აღმოჩენაში.
პრეპროცესინგის ეტაპზე, გავაერთიანე train, test, features და stores ფაილები. CPI და Unemployment სვეტებში NaN მნიშვნელობები შევავსე ffill() მეთოდით, ხოლო markdown სვეტში — 0-ით. კატეგორიული ცვლადები გადავიყვანე ციფრულ მნიშვნელობებად.
ფიჩერული ინჟინერიის პროცესში, დავამატე დროითი მახასიათებლები: წელი, თვე, კვირა, დღე, და სეზონური ცვლადები (sin/cos ტრანსფორმაციით). ასევე შევიტანე დღესასწაულების ფიჩერები (Super Bowl, Labor Day, Thanksgiving, Christmas), lag მნიშვნელობები (1, 2, 4, 8, 12 კვირის წინა გაყიდვები) და მაღაზია-დეპარტამენტის სტატისტიკური მაჩვენებლები, როგორიცაა საშუალო, მედიანა და სტანდარტული გადახრა. დამატებით ჩავამატე ეკონომიკური ცვლადები: CPI, უმუშევრობის მაჩვენებელი და საწვავის ფასები.
მოდელის კონფიგურაცია განისაზღვრა შემდეგნაირად: input dimension შეადგენდა 30-ს (შერჩეული ფიჩერები), patch size განისაზღვრა 12-კვირიანი sequence-ით, d_model — 64, თავების რაოდენობა (n_heads) — 8, ფენების რაოდენობა (n_layers) — 4. გამოყენებული იყო dropout 0.15 და batch size 64.
მოდელის სწავლების შედეგებმა აჩვენა, რომ საბოლოო WMAE დაფიქსირდა 3232.47, რაც მიუთითებს იმაზე, რომ მოდელს საშუალო სიზუსტე ჰქონდა სხვა მოდელებთან შედარებით, თუმცა ეფექტურად მუშაობდა სხვადასხვა დროითი შაბლონების დაფიქსირებასა და სეზონური ცვლილებების გამოვლენაზე.
4. **Prophet** - მარტივად გამოსაყენებელი არქიტექტურა აქვს.  ზოგადი ფორმულა შეგვიძლია ასე წარმოვადგინოთ :
y(t) = trend(t) + seasonality(t) + holiday_effects(t) + error
ტრენდი - აღნიშნავს ზოგადად მონაცემების ცვლილებას : აღმავალი, დაღმავალი თუ სტაბილური.
სეზონურობა არის განმეორებითი პატერნების, იქნება ეს ყოველკვირეული, ყოველწლიური თუ სხვ., დანახვა. 
დღესასწაულები - კონკრეტული დღეების გავლენა მონაცემებზე.
მოდელი ძირითადად იყენებს თარიღსა და გამოსაცნობ მნიშვნელობას, თუ კონკრეტულად არ მიუთითე მნიშვნელოვანი ფიჩერები. არქიტექტურა არაა იდეალური კომპლექსური და არაწრფივი სერიებისთვის. გავუშვი დამატებითი სვეტების გარეშე. მინდოდა დამემატებინა რამე, მაგრამ სწორად არ ამორჩევის შემთხვევაში შედეგს გავაფუჭებდი. woe, iv, rfe და კორელაციის ფილტრს ვფიქრობდი,მაგრამ რეგრესიის ამოცანას პასუხობენ და არა time series. კეგლზე საბოლოოდ wmae მომცა 3000.


**Tree-Based Models** 
1. **LightGBM** წარმოადგენს ensemble არქიტექტურას - ანუ ბევრი სუსტი ხისგან საბოლოოდ ვიღებთ კარგს. არის ძალიან სწრაფი და მოქნილი, მაგრამ overfit დიდი შანსია. 
Preprocessing : დავმერჯე train store  და feature-თან. CPI და Unemployment-ში NaN მნიშვნელობები შევავსე ffill()-ით, რაც უჯრას წინა მნიშვნელობით ავსებს, ხოლო markdown-ში 0-ით, რაც ფასდაკლების არარსებობაზე მიუთითებს. კატეგორიული ცვლადები numerical-ში გადავიყვანე. Date ფორმატი გავასწორე. მოვახდინეთ მონაცემების ნორმალიზაცია/სტანდარტიზაცია. 
Feature Engineering : isHoliday-ს დავუმატე 4 დღესასწაულის აღმნიშვნელი სვეტი : მადლიერების დღე, შობა, super bowl, labor day. ასევე დავამატე days since last და days to next holiday. ასევე lag (1, 2, 3) და moving average სვეტები. Date-ს მიხედვით დავამატე წლის, თვის, კვირისა და დღის აღმნიშვნელი სვეტებიც. 
დავსპლიტე დატა 3 ნაწილად : train, validation და test. დავაtuning learning rate, number of leaves, subsample, colsample_bytree. პლოტებზე ჩანს დარანკული ფიჩერები, და თითოეული პარამეტრის მნიშვნელობა საბოლოო შედეგზე. wmae = 589, თუმცა კეგლზე უფრო მეტი მომცა.

2. ***XGBoost (Extreme Gradient Boosting)*** წარმოადგენს ensemble არქიტექტურას, სადაც მრავალი სუსტი decision tree-ის კომბინაციით იქმნება ძლიერი მოდელი.
Preprocessing: დავმერჯე train, features და stores მონაცემები. CPI და Unemployment-ში NaN მნიშვნელობები შევავსე forward fill-ით, ხოლო markdown სვეტებში 0-ით. კატეგორიული ცვლადები numerical-ში გადავიყვანე Label Encoding-ით.
Feature Engineering: დავამატე დროის ცვლადები (წელი, თვე, კვირა, დღე), ციკლური ცვლადები sin/cos ტრანსფორმაციით, სპეციფიკური დღესასწაულების მარკერები (Super Bowl, Labor Day, Thanksgiving, Christmas), holiday proximity ფიჩერი (2 კვირა წინ/შემდეგ), სტატისტიკური ცვლადები (store/dept/store-dept მიხედვით mean/std/median), markdown ცვლადები (ჯამი, რაოდენობა, ინტენსივობა), ეკონომიკური ცვლადები (CPI/Unemployment რაციო, fuel impact).
Feature Selection: SelectKBest-ით ავარჩიე 50 საუკეთესო ცვლადი f_regression score-ის მიხედვით.
Model Training: გამოვიყენე weighted sampling - holiday პერიოდებში 5-ჯერ მეტი წონით. ჰიპერპარამეტრები: max_depth=8, learning_rate=0.05, n_estimators=2700, early_stopping=50 rounds. ვცადე ჰიპერპარამეტრთა სხვადასხვა კომბინაცია, თუმცა ტესტ სეტზე საუკეთესო მეტრიკა - wmae - აღნიშნულმა კომბინაციამ დააფიქსირა. დავაგენერირე submission ფაილი უნახავ მონაცემებზე და kaggle - ზე ავტვირთე, სადაც დააფიქსირა 3040 wmae (~180 leaderboard-ზე)
შედეგი: Training WMAE: 613.50, Validation WMAE: 1163.57. Overfitting ratio: 1.9x, რაც მსგავსი სირთულის მონაცემებისთვის მისაღები დონეა.

**Classical Statistical Time-Series Models**
1. **ARIMA** -
AutoRegressive მოდელი მიმდინარე მნიშვნელობას წინა მნიშვნელობების წრფივი კომბინაციით იცნობს
Integrated დროის სერიას სტაბილურ საშუალოსა და ვარიაციას ანიჭებს. 
Moving Average წარსული შეცდომების მიხედვით ცვლის დღევანდელ მნიშვნელობას : თუ წინა weekly_sales ძალიან დაბალი მოუვიდა, დღევანდელ მნიშვნელობას გაზრდის 
იგივე პრეპროცესინგი, რაც სხვა მოდელებზე, მაგრამ დავამატეთ Quarter, isMonthStart, isMonthEnd, isWeekend, isHolidaySeason, isBackToSchool სვეტები. ასევე სხვა ეკონომიკური ფიჩერებიც. seasonal_order sarimax-გან განსხვავებით იყო (0, 0, 0, 0), რადგან ეს მოდელი სეზონურობას კარგად ვერ აღიქვამს. საბოლოო wmae = 1936, რაც ამ მოდელისთვის არაა ცუდი.


2. **SARIMA (Seasonal AutoRegressive Integrated Moving Average)** არის კლასიკური დროითი მწკრივების მოდელი, რომელიც ითვალისწინებს სეზონურობას. იგი იყენებს წარსული sales მნიშვნელობებს მომავლის პროგნოზირებისთვის.
Preprocessing: შევაერთე train, features და stores ფაილები. CPI და Unemployment სვეტებში NaN მნიშვნელობები შევავსე ffill() მეთოდით, ხოლო markdown სვეტში - 0-ით. Date ფორმატი გავასწორე და კატეგორიული ცვლადები ციფრულ მნიშვნელობებად გადავიყვანე.
Feature Engineering: დავამატე დროის ფიჩერები (წელი, თვე, კვირა, დღე), Holiday ფიჩერები (Super Bowl, Labor Day, Thanksgiving, Christmas), lag ფიჩერები (1, 2, 4, 8, 12 კვირის განმავლობაში), store/department სტატისტიკები (საშუალო, სტანდარტული გადახრა), markdown-ის ფიჩერები (სრული markdown, აქტიური markdown-ების რაოდენობა), ეკონომიკური ფიჩერები (CPI, Unemployment, Fuel Price) და კონკურენტული ფიჩერები.
მოდელი: გამოვიყენე SARIMA(1,1,1)(1,1,1,52) - სადაც autoregressive order არის 1, differencing - 1, moving average — 1, ხოლო სეზონური პარამეტრები მითითებულია 52 კვირაზე. თითოეული Store-Dept კომბინაციისთვის ცალკე ვაწვრთნიდი მოდელს.
შედეგი: WMAE = 1192.24, MAE = 1110.76. 200 კომბინაციიდან 189 წარმატებით დასრულდა (94.5% success rate).
დამატებით, ჩავატარე ექსპერიმენტები SARIMAX მოდელით, სადაც ჩავრთე 12 დროითი ფიჩერი. ვალიდაცია განხორციელდა 8 კვირიანი holdout-ით და გამოყენებული იყო 50 შემთხვევითი Store-Dept კომბინაცია 3331-დან. შედეგების მიხედვით, 50-დან 46 მოდელი წარმატებით დასრულდა, წარუმატებელი შემთხვევა არ დაფიქსირებულა, რაც 100%-იან წარმატების მაჩვენებელს ნიშნავს. SARIMA მოდელის ვალიდაციის შედეგებით, მიღებული WMAE იყო 1218.20, ხოლო MAE — 1207.74. დამატებითი შეფასებისას MSE შეადგინა 7,174,982.36, RMSE — 2678.62, ხოლო R² მნიშვნელობა იყო 0.9883, რაც მიუთითებს მოდელის მაღალ პროგნოზირების უნარზე.
