# Walmart-Recruiting---Store-Sales-Forecasting

Link to the report on Wand&B - https://wandb.ai/final-project-ml/walmart-sales-prediction/reports/Walmart-Sales-Report--VmlldzoxMzUwNjA1MA

მოცემული გვქონდა Walmart-ის სხვადასხვა რეგიონში მდებარე 45 მაღაზიის გაყიდვების მონაცემები 2010-2012 წლებში. მიზანი იყო თითოეული მაღაზიის მასშტაბით გაყიდვების პროგნოზირება. 
გადმოგვეცემოდა შემდეგი ფაილები : 
train.csv მთავარი სატრენინგო ფაილი 5 სვეტით :  Store, Dept, Date, Weekly_Sales (target), isHoliday.
test.csv სატესტო ფაილი. იგივე რაც train.csv Weekly_Sales გარეშე.
და features.csv - დამატებითი მონაცემებისთვის, როგორიცაა ტემპერატურა, საწვავის ფასი, ფასდაკლების კვირეული, უმუშევრობისა და სამომხმარებლო ფასების ინდექსი.
ასევე გადმოცემული გვქონდა 4 კონკრეტული დღესასწაულის თარიღები: Super Bowl, Labor Day, მადლიერების დღე და შობა.

-----------------------------------------------------------------------------------------------------------------------------
**მონაცემების ანალიზი :** ავაგეთ სხვადასხვა პლოტი, რომ დაგვენახა ზოგადი ტრენდი, სეზონურობა, თუ რა მნიშვნელობა ჰქონდა გაყიდვებზე მაღაზიის ტიპსა თუ დეპარტამენტს, რამდენად განმსაზღვრელი იყო დღესასწაულის პერიოდი, რა კორელაცია იყო ფიჩერებს შორის. გამოვიყენეთ ავტოკორელაციისა და  ნაწილობრივი ავტოკორელაციის ფუნქციაც.

-----------------------------------------------------------------------------------------------------------------------------

Feature Engineering: ახალი მონაცემების შექმნა და მათი ანალიზი.
1) თარიღებიდან მივიღეთ ახალი ცვლადები: წელიწადი, თვე, კვირა, კვირის დღე, კვარტალი, თვის დასაწყისი/დასასრული, დღე თვეში.
2) იმისთვის, რომ სეზონურობა და პერიოდულობა უკეთ აღვიქვათ, თვე, კვირა და კვირის დღე გადავაქციეთ ციკლურ ცვლადებად სინუსისა და კოსინუსის ფუნქციებით.
1-ლი და თვე 12-ე თვეები ერთმანეთთან ახლოს არიან, მაგრამ თუ მხოლოდ რიცხვით წარმოვადგენთ, მათ შორის დიდი განსხვავება გამოვა. ამიტომ, მათი sinus და cosinus ფუნქციებში გადატანა პრობლემას აგვარებს:
sin(2π ∗ value/max value)cos(2π ∗ value/max value). ასე მოდელი ხედავს, რომ დეკემბერი და იანვარი ერთმანეთს ემიჯნება, ისევე, როგორც კვირა და ორშაბათი.
3) დავამატეთ ინდიკატორები სუპერბოულის, შრომის დღის, მადლიერების დღისა და შობისთვის. თვრის დასაწყისი და დასასრული გამოვყავით, როგორც გარდამავალი პერიოდები, რადგან სწორედ ამ დღეებში ხშირად შეიმჩნევა გაყიდვების დინამიკაში მკვეთრი ცვლილებები. ამას ხელს უწყობს ისეთი ფაქტორები, როგორიცაა: ხელფასების გადახდები, მაღაზიების სეზონური ან თვიური ფასდაკლებები, ან მომხმარებელთა ფინანსური ჩვევები თვის დასაწყისსა და ბოლოს. ასევე შევქმენი HolidayProximity ცვლადი, რომელიც აჩვენებს არის თუ არა თარიღი დღესასწაულამდე ან მის შემდეგ 1-2 კვირის შუალედში. მაგალითად, შობის წინ და შემდეგ მომხმარებელი შეიძლება აქტიურობდეს ფასდაკლებებზე.
4) Lag Feature ანუ დაგვიანებული ცვლადი — ეს არის ტექნიკა, რომლის დროსაც დროის სერიის წინა მნიშვნელობა ინახება ახალი ცვლადის სახით და ემატება მოდელს, როგორც პროგნოზირებისთვის გამოსაყენებელი დამატებითი ინფორმაცია. მოდელი ამას ვერ გაიხსენებს, თუ წარსულის მონაცემებს ცალკე არ მივაწვდით. Lag Feature-ები სწორედ ამას აკეთებს — აძლევს მოდელს წინა დროის წერტილების მნიშვნელობებს. ასევე გამოვიყენეთ მოძრავი საშუალო, ე.წ "rolling mean", ეს არის ბოლო N პერიოდის საშუალო მნიშვნელობა.
5) გამოვითვალე მაღაზიის, დეპარტამენტის და მაღაზია+დეპარტამენტის მიხედვით გაყიდვების საშუალო, სტანდარტული გადახრა და მედიანა. მაღაზიის ან დეპარტამენტის დონეზე გაყიდვების სტატისტიკური სურათი საშუალებას აძლევს მოდელს ადვილად გაიგოს რომელ მაღაზიებს ან დეპარტამენტებს აქვთ შედარებით მაღალი ან არასტაბილური გაყიდვები.
6) ჩავამატეთ ფასდაკლებასთან დაკავშირებული ცვლადები (Total_MarkDown), აქტიური ფასდაკლებების რაოდენობა, მაქსიმალური ფასდაკლება და Markdown-ის ინტენსივობა (ფასდაკლებების ოდენობა მაღაზიის ზომის მიხედვით). ფასდაკებები მნიშვნელოვან გავლენას ახდენენ გაყიდვების ზრდაზე. მათი რაოდენობა, მასშტაბი და ინტენსივობა ხშირად პირდაპირ კავშირშია გაყიდვების მოცულობასთან.
7) ეკონომიკური ცვლადების სახით შევქმენით ახალი სვეტები, როგორიცაა CPI / უმუშევრობა, საწვავის ფასი CPI-თან მიმართებაში, და ნორმალიზებული მაჩვენებლები. მნიშვნელოვანი ეკონომიკური ცვლილებები ცალსახად მოქმედებენ გაყიდვებზე.

აღნიშნული ცვლადები მოდელების დატრენინგებისას გამოვიყენეთ სხვადასხვა კომბინაციით, ზოგიერთმა მოდელმა უკეთესი შედეგი აჩვენა მაშინ, როდეას ყველა ცვლადი გამოყენებული იყო ტრენინგში, ზოგიერთისთვის კი ამოვარჩიეთ ისინი feature-importance - ის მიხედვით. ჩავამატეთ წონები დღესასწაულებისთვის (წონა: 5 დღესასწაულებზე და 1 — სხვა დღეებზე).
გავაკეთეთ StandardScaler-ით ნორმალიზაცია, იმ მოდელებისთვის, რომლებისთვისაც ნორმალიზაცია აუცილებელია. ახალა განვიხილივთ მოდელებს ინდივიდუალურად. 


-----------------------------------------------------------------------------------------------------------------------------
**ტესტირებული მოდელები :**

**Deep Learning მოდელები**

1. **N-BEATS** (Neural Basis Expansion Analysis for Time Series) იყენებს ბლოკებს. ეს ბლოკები ერთმანეთზე სტეკივით ლაგდება. მექანიზმი ასეთია : პირველი ბლოკი ცდილობს წარსულის ახსნას (backcast), გარკვეული პატერნის, ტრენდის ან სეზონურობის. შემდეგ იწინასწარმეტყველებს მომავლის გარკვეულ ნაწილს (forecast). მეორე ბლოკი უკვე პირველის backcast-ის გარეშე არსებულ ინფორმაციას შეხედავს და ა.შ. ეს მოდელი N-BEATSx-გან განსხვავებით უყურებს მხოლოდ target მნიშვნელობებს და დამატებით ინფორმაციას არ ითვალისწინებს უკეთესი წინასწარმეტყველებისთვის.
ასე რომ, პრეპროცესინგი აღარ იყო საჭირო. გამოვიყენე neuralforecast ბიბლიოთეკა. შევქმენი ქვეკლასი N_beats, დავარეგულირე gamma (learning rate რამდენად მცირდება), input_size (რამდენი კვირის ინფორმაცია გადაეცემა მოდელს წინასწარმეტყველებისთვის), horizon (რამდენი კვირა უნდა იწინასწარმეტყველოს), stack types (როგორ ბლოკებს იყენებს მოდელი პატერნების დასაჭერად. ძირითადია შემდეგი 3 : identity, trend, seasonality), number of blocks, batch size. საბოლოო wmae მივიღე 2087

--------------------------------------------------------------------------------------------------------------
2. **DLinear (Decomposition Linear)** არის ეფექტური დროის სერიების პროგნოზირებისთვის გათვლილი მოდელი, რომელიც დაფუძნებულია სიგნალის დეკომპოზიციაზე. მონაცემები იყოფა ორ კომპონენტად: ტრენდად და სეზონურობად. ტრენდი არის გრძელვადიანი ტენდენცია, რომელსაც მოდელი გამოითვლის საშუალო მოძრავი საშუალოს (AvgPool1d) გამოყენებით, წინწასწარ განსაზღვრული, გადაცემული პერიოდისთვის. 
სეზონურობა კი გამოყოფილია თავდაპირველი სიგნალისგან ტრენდის გამოკლებით და აჩვენებს მონაცემების პერიოდულ ცვლილებებს.
მოდელი თითოეული ფიჩერისთვის ცალ-ცალკე გამოთვლის ტრენდს და სეზონურობას და თითოეულ კომპონენტზე მიმართავს საკუთარ linear ფენას (მარტივი ხაზოვანი მოდელი), შემდეგ კი მათი შედეგებს აჯამებს საბოლოო პროგნოზის მისაღებად.
DLinear მოდელი მუშაობდა 12 კვირიანი ისტორიის საფუძველზე. პრეპროცესინგის ეტაპზე, დავამატეთ ზემოთ განხილული ცვლადები, რომლებიც მოიცავდა დროის მახასიათებლებს, დღესასწაულებს, lag მნიშვნელობებს, მაღაზია-დეპარტამენტის სტატისტიკას, ფასდაკლებებს და ეკონომიკურ ინდიკატორებს. ფიჩერების არჩევისთვის გამოვიყენე SelectKBest, რის შედეგადაც ავარჩიე საუკეთესო 30 ფიჩერი. მონაცემების ნორმალიზაციისთვის გამოვიყენე StandardScaler. შედეგების მიხედვით, DLinear მოდელმა აჩვენა ვალიდაციის შედეგი WMAE = 2528.44 და R² = 0.92. მოდელი გავწვრთენი Early Stopping-ით 100 ეპოქამდე, ხოლო სასწავლო პროცესში გამოვიყენე Adam optimizer learning rate scheduling-ით, სადაც საწყისი learning rate იყო 0.003 და ეტაპობრივად მცირდებოდა 0.00005-მდე.
პარამეტრები:
Seq-length (წინასწარი ისტორიის ზომა) = 12
Pred-length (პროგნოზის სიგრძე) = 1
Learning rate = 0.003 (კლება 0.00005-მდე)
optimizer	- Adam ოპტიმიზატორი
scheduler step size	- 15 (learning rate-ის ცვლილების ინტერვალი)
scheduler gamma -	0.5 (learning rate-ის შემცირების ფაქტორი)
early stopping	patience = 12 (სწავლების შეჩერება, თუ 12 ეპოქაში გაუმჯობესება არ არის)

--------------------------------------------------------------------------------------------------------------

PatchTST (Patching Time Series Transformer) არის თანამედროვე Deep Learning მოდელი, რომელიც გამოიყენება დროითი მწკრივების პროგნოზირებისთვის და ეფუძნება Transformer არქიტექტურას. მისი ძირითადი პრინციპი მდგომარეობს დროითი მწკრივის პატარა თანმიმდევრობებად — „პატჩებად“ დაყოფაში. თითოეული პატჩი ინდივიდუალურად გადაეცემა Transformer ბლოკებს, სადაც Multi-Head Self-Attention მექანიზმის მეშვეობით ხდება სექვენსის სხვადასხვა მონაკვეთს შორის დამოკიდებულებების დინამიური შეფასება. ეს მიდგომა მოდელს საშუალებას აძლევს ერთდროულად დააფიქსიროს როგორც ლოკალური (პატჩში არსებული მოკლევადიანი კავშირები), ასევე გლობალური (სექვენსის მთელ მანძილზე გამოკვეთილი ტენდენციები) დამოკიდებულებები. PatchTST გამოირჩევა ეფექტური გათვლითი სტრუქტურით, ვინაიდან პატჩებზე დაყოფა ამცირებს საერთო გამოთვლით სირთულეს და ამავე დროს ინარჩუნებს ყურადღების მექანიზმის ძლიერ მხარეს — დროითი ურთიერთკავშირების აღმოჩენას.
მოდელის კონფიგურაცია განისაზღვრა შემდეგნაირად:
input_dim = 30 (შერჩეული ფიჩერების რაოდენობა)
patch_size = 12 (თითოეული პატჩის სიგრძე კვირებში)
d_model = 64 (პატჩის embedding-ის ზომა)
n_heads = 8 (Self-Attention თავების რაოდენობა)
n_layers = 4 (Transformer ფენების რაოდენობა)
dropout = 0.15
batch_size = 64
მოდელის შედეგმა აჩვენა, რომ WMAE დაფიქსირდა 3232.47, რაც მიუთითებს იმაზე, რომ მოდელი აფიქსირებდა დროით შაბლონებს და სეზონურ ცვლილებებს, თუმცა მისი სიზუსტე საშუალო იყო სხვა მოდელებთან შედარებით.
სწავლების პროცესში ტესტირება ჩავატარე რამდენიმე ალტერნატიული კონფიგურაციით, მათ შორის:
n_heads = 6 და 12
d_model = 32 და 128
ropout = 0.1 და 0.25
ასევე ვცადე patch_size-ის ცვლილება 8 და 16 მნიშვნელობებზე. აღნიშნული ვარიანტების უმეტესობაში შედეგები ან გაუარესდა, ან ზუსტად ისეთივე იყო, რაც მიუთითებს, რომ ამ კონკრეტული სეტინგით მოდელმა მიაღწია ოპტიმალურ ბალანსს გამოთვლით ეფექტურობასა და სიზუსტეს შორის.

--------------------------------------------------------------------------------------------------------------
4. **Prophet** - მარტივად გამოსაყენებელი არქიტექტურა აქვს.  ზოგადი ფორმულა შეგვიძლია ასე წარმოვადგინოთ :
y(t) = trend(t) + seasonality(t) + holiday_effects(t) + error
ტრენდი - აღნიშნავს ზოგადად მონაცემების ცვლილებას : აღმავალი, დაღმავალი თუ სტაბილური.
სეზონურობა არის განმეორებითი პატერნების, იქნება ეს ყოველკვირეული, ყოველწლიური თუ სხვ., დანახვა. 
დღესასწაულები - კონკრეტული დღეების გავლენა მონაცემებზე.
მოდელი ძირითადად იყენებს თარიღსა და გამოსაცნობ მნიშვნელობას, თუ კონკრეტულად არ მიუთითე მნიშვნელოვანი ფიჩერები. არქიტექტურა არაა იდეალური კომპლექსური და არაწრფივი სერიებისთვის. გავუშვი დამატებითი სვეტების გარეშე. მინდოდა დამემატებინა რამე, მაგრამ სწორად არ ამორჩევის შემთხვევაში შედეგს გავაფუჭებდი. woe, iv, rfe და კორელაციის ფილტრს ვფიქრობდი,მაგრამ რეგრესიის ამოცანას პასუხობენ და არა time series. კეგლზე საბოლოოდ wmae მომცა 3000.

--------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------

**Tree-Based Models** 
1. **LightGBM** წარმოადგენს ensemble არქიტექტურას - ანუ ბევრი სუსტი ხისგან საბოლოოდ ვიღებთ კარგს. არის ძალიან სწრაფი და მოქნილი, მაგრამ overfit დიდი შანსია. 
Preprocessing : დავმერჯე train store  და feature-თან. CPI და Unemployment-ში NaN მნიშვნელობები შევავსე ffill()-ით, რაც უჯრას წინა მნიშვნელობით ავსებს, ხოლო markdown-ში 0-ით, რაც ფასდაკლების არარსებობაზე მიუთითებს. კატეგორიული ცვლადები numerical-ში გადავიყვანე. Date ფორმატი გავასწორე. მოვახდინეთ მონაცემების ნორმალიზაცია/სტანდარტიზაცია. 
Feature Engineering : isHoliday-ს დავუმატე 4 დღესასწაულის აღმნიშვნელი სვეტი : მადლიერების დღე, შობა, super bowl, labor day. ასევე დავამატე days since last და days to next holiday. ასევე lag (1, 2, 3) და moving average სვეტები. Date-ს მიხედვით დავამატე წლის, თვის, კვირისა და დღის აღმნიშვნელი სვეტებიც. 
დავსპლიტე დატა 3 ნაწილად : train, validation და test. დავაtuning learning rate, number of leaves, subsample, colsample_bytree. პლოტებზე ჩანს დარანკული ფიჩერები, და თითოეული პარამეტრის მნიშვნელობა საბოლოო შედეგზე. wmae = 589, თუმცა კეგლზე უფრო მეტი მომცა.

--------------------------------------------------------------------------------------------------------------

2. ***XGBoost (Extreme Gradient Boosting)*** წარმოადგენს ensemble არქიტექტურას, სადაც მრავალი სუსტი decision tree-ის კომბინაციით იქმნება ძლიერი მოდელი.
დროითი მონაცემებისთვის XGBoost-ის გამოყენებისას მოდელი თითოეულ დროით ეტაპზე პროგნოზირებად მნიშვნელობას Decision Tree-ების საშუალებით აფასებს. განსხვავებით ნეირონული ქსელებისგან, აქ სექვენსური დამოკიდებულება არ ინახება პირდაპირ, თუმცა სწორი ცვლადებით და წონების მექანიზმით შესაძლებელია დროითი ხასიათის ეფექტური დაჭერა.
საწყის ეტაპზე მონაცემთა გაწმენდის შემდეგ, ჰიპერპარამეტრები შევარჩიე დროით სერიებზე ეფექტური მუშაობისთვის, განსაკუთრებით ისეთი პერიოდის გათვალისწინებით, როგორიცაა დღესასწაულები და სეზონური პიკური გაყიდვები. შესაბამისად, holiday პერიოდებში მნიშვნელობებს 5-ჯერ მეტი წონა მივანიჭე, რათა მოდელს უკეთესად ესწავლა განსაკუთრებული დღეების გავლენა.
გამოყენებული  პარამეტრები:
პარამეტრი	-   მნიშვნელობა
max_depth  -	8
learning_rate	 -  0.05
n_estimators	-  2700
early_stopping - 	50 rounds
sampling_weight	-  5x (holiday)

ჰიპერპარამეტრების ტესტირება
სწავლის პროცესში სხვადასხვა ჰიპერპარამეტრების კომბინაცია გამოვცადე. კერძოდ:
max_depth: 4, 6, 8, 10
learning_rate: 0.01, 0.03, 0.05
n_estimators: 1500, 2000, 2700, 3500

ამ ცდებიდან საუკეთესო შედეგი ზემოთ მოყვანილი სეტინგით მივიღე, სადაც ბალანსი ეფექტურობასა და overfitting-ის რისკს შორის ყველაზე ოპტიმალური იყო. დავაგენერირე submission ფაილი უნახავ მონაცემებზე და kaggle - ზე ავტვირთე, სადაც დააფიქსირა 3040 wmae (~180 leaderboard-ზე)
შედეგი: Training WMAE: 613.50, Validation WMAE: 1163.57. Overfitting ratio: 1.9x, რაც მსგავსი სირთულის მონაცემებისთვის მისაღები დონეა.

--------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------

**Classical Statistical Time-Series Models**
1. **ARIMA** -
AutoRegressive მოდელი მიმდინარე მნიშვნელობას წინა მნიშვნელობების წრფივი კომბინაციით იცნობს
Integrated დროის სერიას სტაბილურ საშუალოსა და ვარიაციას ანიჭებს. 
Moving Average წარსული შეცდომების მიხედვით ცვლის დღევანდელ მნიშვნელობას : თუ წინა weekly_sales ძალიან დაბალი მოუვიდა, დღევანდელ მნიშვნელობას გაზრდის 
იგივე პრეპროცესინგი, რაც სხვა მოდელებზე, მაგრამ დავამატეთ Quarter, isMonthStart, isMonthEnd, isWeekend, isHolidaySeason, isBackToSchool სვეტები. ასევე სხვა ეკონომიკური ფიჩერებიც. seasonal_order sarimax-გან განსხვავებით იყო (0, 0, 0, 0), რადგან ეს მოდელი სეზონურობას კარგად ვერ აღიქვამს. საბოლოო wmae = 1936, რაც ამ მოდელისთვის არაა ცუდი.


--------------------------------------------------------------------------------------------------------------

2. **SARIMA (Seasonal AutoRegressive Integrated Moving Average)** წარმოადგენს კლასიკურ სტატისტიკურ მოდელს, რომელიც გამოიყენება დროითი მწკრივების პროგნოზირებისთვის, განსაკუთრებით მაშინ, როცა მონაცემებს აქვთ სეზონური და ტენდენციური კომპონენტები. მოდელი აერთიანებს კომპონენტებს: AR (AutoRegressive) — წარსული მნიშვნელობების გავლენა მიმდინარე მნიშვნელობაზე, MA (Moving Average) — წარსული შეცდომების გავლენა მიმდინარე მნიშვნელობაზე და ამ ყველაფრის სეზონური ვერსიები. გამოვიყენე პარამეტრები:
SARIMA(1,1,1)(1,1,1,52) = SARIMA(p,d,q)(P,D,Q,s)
მოდელი: გამოვიყენე SARIMA(1,1,1)(1,1,1,52) - სადაც autoregressive order არის 1, differencing - 1, moving average — 1, ხოლო სეზონური პარამეტრები მითითებულია 52 კვირაზე. თითოეული Store-Dept კომბინაციისთვის ცალკე ვწვრთნიდი მოდელს. 
შედეგი: WMAE = 1192.24, MAE = 1110.76. 200 კომბინაციიდან 189 წარმატებით დასრულდა (94.5% success rate).

SARIMAX (SARIMA with eXogenous variables) იგივე SARIMA-ს განახლებული ვერსიაა, რომელსაც დამატებით შეუძლია გარე ფაქტორების (exogenous variables) ჩართვა პროგნოზში.
მაგ:თუ გაყიდვებზე გავლენას ახდენს CPI, unemployment, markdown ან დღესასწაულები — SARIMAX საშუალებას გაძლევს ეს ინფორმაცია პირდაპირ ჩართო მოდელში.
ძირითადი უპირატესობა: შეუძლია დროითი მწკრივის გარდა, სხვა ცვლადების ეფექტის გათვალისწინება, განსაკუთრებით ძლიერია, როცა სხვა ცვლილებები მკვეთრად მოქმედებენ დროპთ სერიაზე. 
Sarima - ს გადავედით SARIMAX მოდელზე, სადაც ჩართული იყო 12 დროითი ფიჩერი (მაგ. დღესასწაულები, ტრენდის ინდიკატორები, სეზონური ცვლადები და სხვ.)
Validation-სთვის გამოვიყენე 8-კვირიანი holdout და 50 შემთხვევითი Store-Dept კომბინაცია 3331-დან.
ყველა 50 მოდელი წარმატებით დასრულდა (100%).
შედეგები:
მეტრიკა	მნიშვნელობა
WMAE  -  1218.20
MAE	- 1207.74
RMSE	- 2678.62
R² - 	0.9883
Holiday MAE	- 1240.06
Regular MAE	- 1203.35


